<head>
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
        type='text/css'>
    <style type="text/css">
        body,
        td,
        th,
        tr,
        p,
        a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 18px
        }

        /* th,
        td.demo {
            border-style: solid;
            border-color: #96D4D4;
        } */

        a.cite {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 16px;
            color: rgb(100, 100, 100);
            text-decoration: none;
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 18px;
            /* color: rgb(180, 16, 44); */
        }

        annot {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 18px;
            color: rgb(100, 100, 100);
        }

        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
            color: rgb(180, 16, 44);
            /* color: rgb(0, 0, 0); */
        }

        author {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 20px;
            font-style: italic;
            /* color : rgb(180, 16, 44) */
            color: rgb(0, 0, 0);
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 25px;
            color: rgb(180, 16, 44);
            /* color: rgb(0, 0, 0); */
        }

        subheading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 22px;
            /* font-style:italic; */
            color: rgb(180, 16, 44)
                /* color: rgb(0, 0, 0); */
        }

        li {
            line-height: 25px;
        }

        li.contents {
            line-height: 30px;
        }

        .footer {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
            opacity: 0.75;
            color: #777;
        }
    </style>
    <!-- <script
        src="https://cdn.jsdelivr.net/combine/npm/tone@14.7.58,npm/@magenta/music@1.23.1/es6/core.js,npm/focus-visible@5,npm/html-midi-player@1.4.0"></script> -->
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <link rel="icon" type="image/png" href="../../images/music.ico">
    <title>Singing Voice Conversion</title>
</head>

<body>
    <table width="960" border="0" align="center" cellspacing="0" cellpadding="0">
        <tr>
            <td>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12"
                    style="table-layout:fixed;">
                    <tr>
                        <td>
                            <papertitle>Singing Voice Conversion Tutorial</papertitle>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <b>
                                <author>Xueyao Zhang</author>
                            </b>
                            <p>
                                <!-- CSC3160/MDS6002, Spring 2023 -->
                                The Chinese University of Hong Kong, Shenzhen
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <heading>Contents</heading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <li>What is Singing Voice Conversion?</li>
                            <li style="text-indent:20px; list-style-type: circle">Intra-singer conversion</li>
                            <li style="text-indent:20px; list-style-type: circle">Inter-singer conversion</li>
                            <li style="text-indent:20px; list-style-type: circle">Cross-domain conversion</li>
                            <!-- <br> -->
                            <li class="contents">Application and User Scenarios</li>
                            <li style="text-indent:20px; list-style-type: circle">Imitation and Entertainment</li>
                            <li style="text-indent:20px; list-style-type: circle">Singing Voice Beautification</li>
                            <li style="text-indent:20px; list-style-type: circle">Education</li>
                            <li style="text-indent:20px; list-style-type: circle">Creative Art</li>
                            <!-- <br> -->
                            <li class="contents">Recommended Datasets</li>
                            <!-- <br> -->
                            <li class="contents">Recommended Papers</li>
                            <li style="text-indent:20px; list-style-type: circle">Paradigm of the conversion framework
                                (Basics)</li>
                            <li style="text-indent:20px; list-style-type: circle">To model singer independent features
                            </li>
                            <li style="text-indent:20px; list-style-type: circle">To model singer dependent features
                            </li>
                            <li style="text-indent:20px; list-style-type: circle">To introduce singing voice domain
                                knowledge</li>
                            <li class="contents">Baseline: WORLD-based SVC</li>
                            <li style="text-indent:20px; list-style-type: circle">What is WORLD?</li>
                            <li style="text-indent:20px; list-style-type: circle">Overview</li>
                            <li style="text-indent:20px; list-style-type: circle">Implementation Details</li>
                            <li style="text-indent:20px; list-style-type: circle">Demo</li>

                            <!-- <li class="contents">CSC3160/MDS6002 Project Description</li>
                            <li style="text-indent:20px; list-style-type: circle">Requirements</li>
                            <li style="text-indent:20px; list-style-type: circle">Potential Ideas</li> -->
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <heading>What is Singing Voice Conversion?</heading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                Sing voice conversion (SVC) is to convert <b>singing voice</b> to our <b>desired
                                    targets</b>.
                                There are three common SVC tasks:
                                <li style="text-indent:20px">
                                    <b>Intra-singer conversion</b>: To convert a singer's voice to a desired timbre
                                    (eg: to a more beautiful voice).
                                </li>
                                <li style="text-indent:20px">
                                    <b>Inter-singer conversion</b>: To convert a singer's voice to another singers'
                                    one.
                                </li>
                                <li style="text-indent:20px">
                                    <b>Cross-domain conversion</b>: It means the source audio and target audio are from
                                    different domains. For example, to convert a speech voice to singing voice.
                                </li>
                            </p>
                            <p>
                                Here are some examples:
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Intra-singer conversion</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                <b>Source</b>:
                                <br><br>
                                <audio controls>
                                    <source src="./data/LiJiawei/LiJiawei-source.wav" type="audio/mpeg">
                                </audio>
                            </p>
                            <p>
                                <b>Target</b>:
                                <br><br>
                                <audio controls>
                                    <source src="./data/LiJiawei/LiJiawei-target.wav" type="audio/mpeg">
                                </audio>
                            </p>
                            <p>
                                <a class="cite"
                                    href="https://www.bilibili.com/video/BV1VW4y167ip/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=85eed151e987f4dc517690ea06127710">Jiawei
                                    Li. Use
                                    more chest resonance for increasing your singing’s power. Bilibili,
                                    2022.
                                </a>

                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Inter-singer conversion</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                <b>Source</b>:
                                <br><br>
                                <audio controls>
                                    <source src="./data/InterSinger/source.wav" type="audio/mpeg">
                                </audio>
                            </p>
                            <p>
                                <b>Reference</b>:
                                <br><br>
                                <audio controls>
                                    <source src="./data/InterSinger/reference.wav" type="audio/mpeg">
                                </audio>
                            </p>
                            <p>
                                <b>Target</b> (source singer's content + reference singer's timbre):
                                <br><br>
                                <audio controls>
                                    <source src="./data/InterSinger/target.wav" type="audio/mpeg">
                                </audio>
                            </p>
                            <p>
                                <a class="cite">Chao Wang, et al. Towards High-Fidelity Singing Voice Conversion with
                                    Acoustic Reference
                                    and Contrastive Predictive Coding. InterSpeech 2022.
                                </a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Cross-domain conversion</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                <b>Source</b> (singing voice):
                                <br><br>
                                <audio controls>
                                    <source src="./data/CrossDomain/source.wav" type="audio/mpeg">
                                </audio>
                            </p>
                            <p>
                                <b>Reference</b> (speech):
                                <br><br>
                                <audio controls>
                                    <source src="./data/CrossDomain/reference.wav" type="audio/mpeg">
                                </audio>
                            </p>
                            <p>
                                <b>Target</b> (source singer's content + reference speaker's timbre):
                                <br><br>
                                <audio controls>
                                    <source src="./data/CrossDomain/target.wav" type="audio/mpeg">
                                </audio>
                            </p>
                            <p>
                                <a class="cite">Heyang Xue, et al. Learn2Sing 2.0: Diffusion and Mutual
                                    Information-Based Target Speaker SVS by Learning from Singing Teacher. InterSpeech
                                    2022.
                                </a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <heading>Application and User Scenarios</heading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Imitation and Entertainment</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <i>Impression Show</i> to various singers:
                            <p>
                                <video width="600" controls>
                                    <source src="./data/App/JieJiuShiNvWang.mp4" type="video/mp4">
                                </video>
                                <br>
                                <a class="cite"
                                    href="https://www.bilibili.com/video/BV1eR4y1A75e/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=85eed151e987f4dc517690ea06127710">Ya
                                    Yue. Arrangements for 姐就是女王 as different singers' styles. Bilibili, 2022. </a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Singing Voice Beautification</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Tone Tuning:
                            <p>
                                <video width="600" controls>
                                    <source src="./data/App/ToneTuning.mp4" type="video/mp4">
                                </video>
                                <br>
                                <a class="cite"
                                    href="https://www.bilibili.com/video/BV1uJ411q7xp/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=85eed151e987f4dc517690ea06127710">Magic
                                    of Tuner. Bilibili, 2022. </a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Education</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Vocal music teaching:
                            <p>
                                <video width="600" controls>
                                    <source src="./data/LiJiawei/parallel.mp4" type="video/mp4">
                                </video>
                                <br>
                                <a class="cite"
                                    href="https://www.bilibili.com/video/BV1VW4y167ip/?spm_id_from=333.1007.top_right_bar_window_custom_collection.content.click&vd_source=85eed151e987f4dc517690ea06127710">Jiawei
                                    Li. Use
                                    more chest resonance for increasing your singing’s power. Bilibili,
                                    2022.
                                </a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Creative Art</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Translate vocal music to instrumental music:
                            <p>
                                <video width="600" controls>
                                    <source src="./data/App/BeatIt.mp4" type="video/mp4">
                                </video>
                                <br>
                                <a class="cite"
                                    href="https://www.bilibili.com/video/BV1ZJ411y7dy/?spm_id_from=333.999.0.0&vd_source=85eed151e987f4dc517690ea06127710">Peter
                                    Bence. Beat it (piano cover). Bilibili, 2022. </a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <heading>Recommended Datasets</heading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                <li><b>NUS-48E</b> (English): 2.8 hours, 12 singers, 20 unique songs. <annot>[1]</annot>
                                </li>
                                <!-- <br> -->
                                <li><b>Opencpop</b> (Mandarian): 5.25 hours, 1 singers, 100 unique songs. <annot>[2]
                                    </annot>
                                </li>
                                <!-- <br> -->
                                <li><b>M4Singer</b> (Mandarian): 30.59 hours, 19 singers, 419 unique songs. <annot>[3]
                                    </annot>
                                </li>
                                <!-- <br> -->
                            </p>
                            <p>
                                <a class="cite">
                                    [1] Zhiyan Duan, et al. The NUS sung and spoken lyrics corpus: A
                                    quantitative comparison of singing and speech. APSIPA 2013. <br>
                                    [2] Yu Wang, et al. Opencpop: A High-Quality Open Source Chinese Popular Song Corpus
                                    for Singing Voice Synthesis. InterSpeech 2022. <br>
                                    [3] Lichao Zhang, et al. M4Singer: a Multi-Style, Multi-Singer and Musical Score
                                    Provided Mandarin Singing Corpus. NeurIPS 2022.
                                </a>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <heading>Recommended Papers</heading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            Here I listed some SVC papers with <b>non-parallel</b> data. "Non-parallel" means that
                            we do not have the <i>(source audio, target audio)</i> pairs data. You can refer to <a
                                href="./data/UnparallelSVC.pdf">this review</a> to know more about it.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Paradigm of the conversion framework (Basics)</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                <li>
                                    Xin Chen, et al. Singing Voice Conversion with Non-parallel Data. IEEE MIPR 2019.
                                </li>
                                <li>
                                    Eliya Nachmani, et al. Unsupervised Singing Voice Conversion. InterSpeech 2019.
                                </li>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>To model singer independent features</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                <li>
                                    Zhonghao Li, et al. PPG-Based Singing Voice Conversion with Adversarial
                                    Representation Learning. ICASSP 2021.
                                </li>
                                <li>
                                    Jordi Bonada, et al. Semi-supervised Learning for Singing Synthesis Timbre. ICASSP
                                    2021.
                                </li>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>To model singer dependent features</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                <li>
                                    Xu Li, et al. A Hierarchical Speaker Representation Framework for One-shot Singing
                                    Voice Conversion. InterSpeech 2022.
                                </li>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>To introduce singing voice domain knowledge</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                <li>
                                    Chengqi Deng et al. PitchNet: Unsupervised Singing Voice Conversion with Pith
                                    Adversarial Network. ICASSP 2020.
                                </li>
                                <li>
                                    Haohan Guo et al. Improving Adversarial Waveform Generation Based Singing Voice
                                    Conversion with Harmonic Signals. ICASSP 2022.
                                </li>
                                <li>
                                    Tae-Woo Kim et al. Adversarial Multi-Task Learning for Disentangling Timbre and
                                    Pitch in Singing Voice Synthesis. InterSpeech 2022.
                                </li>
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <heading>Baseline: WORLD-based SVC</heading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            All the source code of this baseline can be seen <a
                                href="https://github.com/SLPcourse/Singing-Voice-Conversion">here</a>.
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>What is WORLD?</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                WORLD <a class="cite">[1]</a> is a classical vocoder in Digital Signal Processing (DSP).
                                It supposes there are three acoustic components of an audio: Fundamental frequency (F0),
                                Spectral envelope (SP), and Aperiodic
                                parameter (AP). It can be considered not only an extractor, which can extract F0, SP,
                                and AP efficiently, but also a synthesizer, which can synthesis an audio by
                                incorporating
                                the three.
                            </p>
                            <p>
                                Compared to the recent neural-based vocoders (such as WaveNet, WaveRNN, Hifi-GAN,
                                Diffwave, etc.),
                                WORLD is more like a white box and is more controllable and manipulable, while its
                                synthesis
                                quality is worse. We can easily adjust the input parameters to change the synthesized
                                audios. For example, given such a male singing voice:
                            </p>
                            <p>
                                <audio controls src="./data/WORLD/LiJian/source.wav">
                                </audio>
                            </p>
                            <p>
                                We can keep the F0 unchanged, and convert it to a robot-like voice:
                            </p>
                            <p>
                                <audio controls src="./data/WORLD/LiJian/pitch_all_100.wav">
                                </audio>
                            </p>
                            <p>
                                Or, we can also increase the F0 two times, divide the SP by 1.2, and
                                convert it to a female-like voice:
                            </p>
                            <p>
                                <audio controls src="./data/WORLD/LiJian/pitch_times_2_sp_div_1.2.wav">
                                </audio>
                            </p>
                            <p>
                                The official code of WORLD has been released <a
                                    href="https://github.com/mmorise/World">here</a>. You can play it, and manipulate
                                the voice as you like!
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <a class="cite">
                                [1] Masanori Morise, et al. WORLD: A Vocoder-Based High-Quality Speech Synthesis
                                System for Real-Time Applications. IEICE Trans. Inf. Syst. 2016.
                            </a>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Overview</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td align="center">
                            <img src="./data/framework.png" width="1000">
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                The conversion framework of the figure above is proposed by <a class="cite">[1]</a>.
                                There are two main
                                modules of
                                it, <i>Content Extractor</i> and <i>Singer-specific Synthesizer</i>. Given a source
                                audio,
                                firstly the <i>Content Extractor</i> is aim to extract content features (i.e.,
                                <b>singer independent
                                    features</b>) from the audio. Then, the <i>Singer-specific Synthesizer</i> is
                                designed to
                                inject the <b>singer dependent features</b> for the synthesis, so that the target
                                audio can be able to capture the singer's characteristics.
                            </p>
                            <p>
                                The authors of <a class="cite">[1]</a> assume that among the three components of
                                WORLD (i.e., F0, AP, and SP), only SP is singer dependent and should be modeled by the
                                <i>Singer-specific Synthesizer</i>, while the other two can be
                                considered pure content features. Based on that, we can utilize the following two stages
                                to conduct <b>any-to-one</b> conversion:
                                <li style="text-indent:20px;">
                                    <b>Acoustics Mapping Training</b> (Training Stage): This stage is to train the
                                    mapping from the
                                    textual
                                    content features (eg: PPG) to the target singer's acoustic features (eg: SP or
                                    MCEP). The training model can be a neural network like Bi-LSTM <a
                                        class="cite">[1]</a>.
                                </li>
                                <li style="text-indent:20px;">
                                    <b>Inference and Conversion</b> (Conversion Stage): Given any source singer's audio,
                                    firstly, extract its content features including F0, AP, and textual content
                                    features.
                                    Then, use the model of training stage to infer the converted acoustic features (SP
                                    or MCEP).
                                    Finally, given F0, AP, and the converted SP, we
                                    utilize WORLD as vocoder to synthesis the converted audio.
                                </li>
                            </p>

                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Implementation Details</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <p>
                                The experiment setting is many-to-one conversion. Specifically, we consider <a
                                    href="https://wenet.org.cn/opencpop/">Opencpop</a>
                                (which is a single singer dataset) as target singer and use <a
                                    href="https://github.com/M4Singer/M4Singer">M4Singer</a> (which is a 19-singer
                                dataset)
                                as source singers.
                            </p>
                            <p>
                                We adopt a <a
                                    href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder">python
                                    wrapper of WORLD</a> to extract F0, AP, and SP, and to synthesis audios. We use <a
                                    href="https://github.com/sp-nitech/diffsptk">diffsptk</a> to transform between SP
                                and
                                MCEP. We utilize the last layer encoder's output of <a
                                    href="https://github.com/openai/whisper">Whisper</a> as the content features
                                (which is 1024d). During training stage, we use a 6-layer Transformer to train the
                                mapping
                                from
                                whisper
                                features to 40d MCEP features.
                            </p>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Demo</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <b>Target Singer Samples</b> (Opencpop):
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <table width="100%" border="0" cellspacing="0" cellpadding="12">
                                <tr>
                                    <td>
                                        <audio controls src="./data/Opencpop/2001000021.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/Opencpop/2032001221.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/Opencpop/2080002938.wav">
                                        </audio>
                                    </td>
                                </tr>
                            </table>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <b>Conversion Samples</b> (Convert different singers of M4Singer to Opencpop):
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <table width="100%" border="1" cellspacing="0" cellpadding="12"
                                style="border-color: rgb(250, 250, 250);">
                                <tr>
                                    <td align="center">
                                        <b>Source</b>
                                    </td>
                                    <td align="center">
                                        <b>Ground Truth</b>
                                    </td>
                                    <td align="center">
                                        <b>WORLD</b>
                                    </td>
                                    <td align="center">
                                        <b>Converted Result</b>
                                    </td>
                                </tr>
                                <tr>
                                    <td align="center">
                                        Soprano-2
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Soprano-2_可惜不是你_0000.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Soprano-2_可惜不是你_0000_world.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Soprano-2_可惜不是你_0000_pred.wav">
                                        </audio>
                                    </td>
                                </tr>
                                <tr>
                                    <td align="center">
                                        Soprano-3
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Soprano-3_一抹夕阳_0000.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Soprano-3_一抹夕阳_0000_world.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Soprano-3_一抹夕阳_0000_pred.wav">
                                        </audio>
                                    </td>
                                </tr>
                                <tr>
                                    <td align="center">
                                        Alto-4
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Alto-4_一首简单的歌_0000.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Alto-4_一首简单的歌_0000_world.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Alto-4_一首简单的歌_0000_pred.wav">
                                        </audio>
                                    </td>
                                </tr>
                                <tr>
                                    <td align="center">
                                        Alto-5
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Alto-5_一千年以后_0000.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Alto-5_一千年以后_0000_world.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Alto-5_一千年以后_0000_pred.wav">
                                        </audio>
                                    </td>
                                </tr>
                                <tr>
                                    <td align="center">
                                        Tenor-6
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Tenor-6_像我这样的人_0000.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Tenor-6_像我这样的人_0000_world.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Tenor-6_像我这样的人_0000_pred.wav">
                                        </audio>
                                    </td>
                                </tr>
                                <tr>
                                    <td align="center">
                                        Tenor-7
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Tenor-7_一生守候_0000.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Tenor-7_一生守候_0000_world.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Tenor-7_一生守候_0000_pred.wav">
                                        </audio>
                                    </td>
                                </tr>
                                <tr>
                                    <td align="center">
                                        Bass-2
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Bass-2_DEAR_JOHN_0000.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Bass-2_DEAR_JOHN_0000_world.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Bass-2_DEAR_JOHN_0000_pred.wav">
                                        </audio>
                                    </td>
                                </tr>
                                <tr>
                                    <td align="center">
                                        Bass-3
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Bass-3_像我这样的人_0000.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Bass-3_像我这样的人_0000_world.wav">
                                        </audio>
                                    </td>
                                    <td>
                                        <audio controls src="./data/WORLD/Bass-3_像我这样的人_0000_pred.wav">
                                        </audio>
                                    </td>
                                </tr>
                            </table>
                        </td>
                    </tr>
                    <!-- <tr>
                        <td>
                            <heading>CSC3160/MDS6002 Project Description</heading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Requirements</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            TBD (eg: the target singer should be <b>Opencpop singer</b>)
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <subheading>Potential Ideas</subheading>
                        </td>
                    </tr>
                    <tr>
                        <td>
                            <li>To inject <b>singing voice domain knowledge</b> (eg: pitch,
                                duration,
                                score,
                                timbre
                                features) in to the model.</li>
                            <li>To explore the impact of different <b>vocoders</b>.</li>
                            <li>To design better <b>evaluation metrics</b>. For example, more robust objective
                                evaluation, or
                                more efficient and friendly subjective evaluation.</li>
                            <li>To improve the <b>explainability</b> of SVC. For example, visualize the different module
                                of
                                the deep learning framework.
                        </td>
                    </tr> -->
                </table>

                <table width="100%" align="center" border="0" cellpadding="12">
                    <tr>
                        <td width="100%" valign="center">
                            <p class="footer">
                                Design: <a href="https://www.zhangxueyao.com/" target="_blank"
                                    style="color: #777; font-size: 14px;">Xueyao Zhang</a>
                                <br>Last updated:
                                <script>
                                    t = new Date(document.lastModified).toLocaleDateString()
                                    document.write(t);
                                </script>
                                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
                                <span id="busuanzi_container_page_pv">#Views: <span
                                        id="busuanzi_value_page_pv"></span></span> (2022/7/6~)
                            </p>
                        </td>
                    </tr>
                </table>
            </td>
        </tr>
    </table>
</body>