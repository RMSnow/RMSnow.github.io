<!--
 * @Author: Jon Barron
 * @Date: 2019-05-11 22:15:22
 * @Editors: whyisyoung
 * @EditTime: 2020-10-23 10:57:25
 * @LastEditors: RMSnow xueyao_98@foxmail.com
 * @LastEditTime: 2023-10-28 00:44:27
 -->
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<html>

<head>
  <meta name=viewport content="width=device-width">
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <meta name="google-site-verification" content="p7SNRHPF7y83Q-nNBLkrxFhAAosW2t40unwTxByZ0vo" />
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */

    span.tag {
      font-size: 11px;
      color: #FFFFFF;
      /* color: #07889b; */
      background-color: #0076DF;
      box-shadow: 2px 2px 1px #E0E0E0;
      padding: 1px 5px 2px 5px;
    }

    a {
      color: #1772d0;
      /* color: #07889b; */
      text-decoration: none;
    }

    a.black {
      color: #000000;
      /* color: #07889b; */
      text-decoration: none;
    }

    a:focus,
    a:hover {
      /* color: #e37222; #f09228; */
      color: rgb(180, 16, 44);
      text-decoration: none;
    }

    body,
    td,
    th,
    tr,
    p,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px
    }

    strong {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }

    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
      /* color: #e3225c; */
      color: rgb(180, 16, 44);
    }

    subheading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 18px;
      font-style: italic;
      /* color: #e3225c; */
      color: rgb(180, 16, 44);
    }

    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: bold;
    }

    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }

    .footer {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 14px;
      opacity: 0.75;
      color: #777;
    }

    .one {
      width: 160px;
      height: 160px;
      position: relative;
    }

    .two {
      width: 160px;
      height: 160px;
      position: absolute;
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    .fade {
      transition: opacity .2s ease-in-out;
      -moz-transition: opacity .2s ease-in-out;
      -webkit-transition: opacity .2s ease-in-out;
    }

    span.highlight {
      background-color: #ffffd0;
    }

    span.artifact {
      color: #6cb41b;
      padding: 1px;
    }

    span.underline {
      border-bottom: 1px solid black;
      padding-bottom: 1px;
    }

    span.tldr {
      color: #555555;
    }

    em.highlight {
      color: #e37222;
    }
  </style>
  <link rel="icon" type="image/png" href="images/music.ico">
  <title>Xueyao Zhang</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
    type='text/css'>
</head>

<body>
  <table width="960" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <!-- Publications Begin -->
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="12">
          <tr>
            <td>
              <heading>Full Publications</heading>
            </td>
          </tr>
        </table>
        <table width="100%" align="center" border="0" cellpadding="12" style="table-layout:fixed;">
          <td>
            <subheading>Singing Voice Processing</subheading>
          </td>
          <tr>
            <td valign="center">
              <span class="tag">ML4Audio @ NeurIPS 2023</span>&nbsp;&nbsp;
              <papertitle>Leveraging Content-based Features from Multiple Acoustic Models for Singing Voice Conversion
              </papertitle>
              <br>
              <span class="underline">Xueyao Zhang</span>, Yicheng Gu, Haopeng Chen, Zihao Fang, Lexiao Zou, <a
                class="black" href="https://scholar.google.com/citations?user=KNqxVT0AAAAJ&hl=zh-CN">Liumeng Xue</a>, <a
                class="black" href="https://drwuz.com/">Zhizheng Wu</a>
              <br>
              <i>Machine Learning for Audio Workshop (ML4Audio) at NeurIPS 2023 </i>
              <br>
              <!-- <a href="https://doi.org/10.1145/3503161.3548084" target="_blank">PDF</a> / -->
              <a href="https://arxiv.org/pdf/2310.11160.pdf" target="_blank">Preprint</a> /
              <!-- <a href="https://github.com/RMSnow/HAT" target="_blank">Code</a> / -->
              <!-- <a href="data/HAT/slides.pdf" target="_blank">Slides</a> / -->
              <a href="data/MultipleContentsSVC/index.html" target="_blank">Demo</a>
              <br>
              <span class="tldr">TL;DR: We propose to utilize multiple content features for singing voice conversion.
              </span>
            </td>
          </tr>
          <td>
            <subheading>Music Generation</subheading>
          </td>
          <tr>
            <td valign="center">
              <span class="tag">MM 2022</span>&nbsp;&nbsp;
              <papertitle>Structure-Enhanced Pop Music Generation via Harmony-Aware Learning</papertitle>
              <br>
              <span class="underline">Xueyao Zhang</span>, <a class="black"
                href="https://scholar.google.com/citations?hl=zh-CN&user=vH9YLsAAAAAJ">Jinchao Zhang</a>, Yao Qiu, Li
              Wang, Jie Zhou
              <br>
              <i>Proceedings of the 30th ACM International Conference on Multimedia (Acceptance Rate:
                690/2473=27.9%)</i>
              <br>
              <a href="https://arxiv.org/pdf/2109.06441.pdf" target="_blank">Preprint</a> /
              <a href="https://github.com/RMSnow/HAT" target="_blank">Code</a> /
              <a href="data/HAT/demo.html" target="_blank">Demo</a>
              <br>
              <span class="tldr">TL;DR: We propose to learn harmony for generating form- and texture- enhanced pop
                music. </span>
            </td>
          </tr>
          <td>
            <subheading>Fake News Detection</subheading>
          </td>
          <tr>
            <td valign="center">
              <span class="tag">ACL 2022</span>&nbsp;&nbsp;
              <papertitle>Zoom Out and Observe: News Environment Perception for Fake News Detection</papertitle>
              <br>
              <a class="black" href="https://sheng-qiang.github.io/">Qiang Sheng</a>, <a class="black"
                href="https://scholar.google.com/citations?user=fSBdNg0AAAAJ">Juan Cao</a>, <span
                class="underline">Xueyao Zhang</span>, <a class="black"
                href="https://scholar.google.com/citations?user=PfmGvVQAAAAJ">Rundong Li</a>, <a class="black"
                href="https://scholar.google.com/citations?user=hGZwK0cAAAAJ">Danding Wang</a>, and <a class="black"
                href="https://easezyc.github.io/">Yongchun Zhu</a>
              <br>
              <i>Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics</i>
              <br>
              <a href="https://aclanthology.org/2022.acl-long.311.pdf">PDF</a> /
              <a href="https://sheng-qiang.github.io/data/NEP-Poster.pdf">Poster</a>
              /
              <a href="https://github.com/ICTMCG/News-Environment-Perception">Code</a>
              /
              <a href="https://www.bilibili.com/video/BV1MS4y1e7PY">Chinese Video</a>
              /
              <a href="https://mp.weixin.qq.com/s/aTFeuCYIpSoazeRi52jqew">Chinese Blog</a>
              <br>
              <span class="tldr">TL;DR: For the first time, we propose to perceive signals from the news environment for
                fake news detection. </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">CIKM 2021</span>&nbsp;&nbsp;
              <papertitle>Integrating Pattern- and Fact-based Fake News Detection via Model Preference Learning
              </papertitle>
              <br>
              <a class="black" href="https://sheng-qiang.github.io/">Qiang Sheng</a>*, <span class="underline">Xueyao
                Zhang</span>*, <a class="black" href="https://scholar.google.com/citations?user=fSBdNg0AAAAJ">Juan
                Cao</a>, and Lei Zhong (*: Equal Contribution)
              <br>
              <i>Proceedings of the 30th ACM International Conference on Information and Knowledge Management
                (Acceptance Rate: 271/1251=21.7%)</i>
              <br>
              <a href="https://dl.acm.org/doi/10.1145/3459637.3482440">PDF</a> /
              <a href="data/PrefFEND/cikm2021-PrefFEND-poster.pdf">Poster</a> /
              <a href="https://github.com/ICTMCG/Pref-FEND">Code</a> /
              <a href="https://zhuanlan.zhihu.com/p/414464291">Chinese Blog</a>
              <br>
              <span class="tldr">TL;DR: We propose a graph-based model preference learning framework to separately
                handle the pattern and fact indicators in fake news detection. </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">ACL 2021</span>&nbsp;&nbsp;
              <papertitle>Article Reranking by Memory-enhanced Key Sentence Matching for Detecting Previously
                Fact-checked Claims</papertitle>
              <br>
              <a class="black" href="https://sheng-qiang.github.io/">Qiang Sheng</a>, <a class="black"
                href="https://scholar.google.com/citations?user=fSBdNg0AAAAJ">Juan Cao</a>, <span
                class="underline">Xueyao Zhang</span>, <a class="black" href="http://lixirong.net/">Xirong Li</a>, and
              Lei Zhong
              <br>
              <i>Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Computational
                Linguistics and the 11th International Joint Conference on Natural Language Processing (Acceptance Rate:
                571/2327=24.5%)</i>
              <br>
              <a href="https://aclanthology.org/2021.acl-long.425.pdf">PDF</a> /
              <a href="data/MTM/acl2021-MTM-poster.pdf">Poster</a> /
              <a href="https://github.com/ICTMCG/MTM">Code</a> /
              <a href="https://zhuanlan.zhihu.com/p/393615707">Chinese Blog</a>
              <br>
              <span class="tldr">TL;DR: We detect previously fact-checked claims by matching them against the key
                sentences in fact-checking articles. </span>
            </td>
          </tr>
          <tr>
            <td valign="center">
              <span class="tag">WWW 2021</span>&nbsp;&nbsp;
              <papertitle>Mining Dual Emotion for Fake News Detection</papertitle>
              <br>
              <span class="underline">Xueyao Zhang</span>, <a class="black"
                href="https://scholar.google.com/citations?user=fSBdNg0AAAAJ">Juan Cao</a>, <a class="black"
                href="http://lixirong.net/">Xirong Li</a>, <a class="black" href="https://sheng-qiang.github.io/">Qiang
                Sheng</a>, Lei Zhong, and <a class="black" href="http://www.cs.iit.edu/~kshu/">Kai Shu</a>
              <br>
              <i>Proceedings of the 30th Web Conference (Acceptance Rate: 357/1736=20.6%)</i>
              <br>
              <a href="data/DualEmotion/www2021-dual-emotion-paper.pdf">PDF</a> /
              <a href="https://github.com/RMSnow/WWW2021">Code</a> /
              <a href="data/DualEmotion/www2021-dual-emotion-slides.pdf">Slides</a> /
              <a href="data/DualEmotion/www2021-dual-emotion-video.mp4">Video</a> /
              <a href="https://www.bilibili.com/video/BV13o4y1m7c3">Chinese Video</a>
              <br>
              <span class="tldr">TL;DR: We leverage both publisher emotion and social emotion for fake news detection.
              </span>
            </td>
          </tr>


        </table>
        <!-- Publications End -->

      </td>
    </tr>
  </table>
</body>

</html>